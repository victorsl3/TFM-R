{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_diabetes, load_digits, load_wine, load_breast_cancer, fetch_california_housing, fetch_covtype, fetch_20newsgroups, fetch_olivetti_faces, fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, load_diabetes, load_digits, load_linnerud, load_wine, load_breast_cancer, fetch_covtype, fetch_california_housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_dataset(name):\n",
    "#     datasets = {\n",
    "#         'iris': load_iris,\n",
    "#         'diabetes': load_diabetes,\n",
    "#         'digits': load_digits,\n",
    "#         'wine': load_wine,\n",
    "#         'breast_cancer': load_breast_cancer,\n",
    "#         'california_housing': fetch_california_housing,\n",
    "#         'forest_covertypes': fetch_covtype,\n",
    "\n",
    "#     }\n",
    "\n",
    "#     if name not in datasets:\n",
    "#         raise ValueError(f\"Dataset '{name}' no disponible.\")\n",
    "\n",
    "#     # Cargar el conjunto de datos\n",
    "#     if name == '20_newsgroups':\n",
    "#         data = datasets[name](subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "#         # Aquí necesitarías preprocesar el texto para convertirlo en características numéricas\n",
    "#         # Por simplicidad, se omite este paso\n",
    "#     else:\n",
    "#         data = datasets[name]()\n",
    "\n",
    "#     if name in ['olivetti_faces', 'lfw_people']:\n",
    "#         # Estos conjuntos de datos son principalmente para tareas de reconocimiento de imágenes\n",
    "#         X, y = data.data, data.target\n",
    "#     elif name == '20_newsgroups':\n",
    "#         # Preprocesamiento especial para texto, si es necesario\n",
    "#         X, y = data.data, data.target\n",
    "#     else:\n",
    "#         X, y = data.data, data.target\n",
    "\n",
    "#     # Dividir el conjunto de datos en entrenamiento, validación y prueba\n",
    "#     X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "#     return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_tabular_dataset(name):\n",
    "    dataset_loaders = {\n",
    "        'iris': load_iris,\n",
    "        'diabetes': load_diabetes,\n",
    "        'digits': load_digits,\n",
    "        'linnerud': load_linnerud,\n",
    "        'wine': load_wine,\n",
    "        'breast_cancer': load_breast_cancer,\n",
    "        'covtype': fetch_covtype,\n",
    "        'california_housing': fetch_california_housing,\n",
    "    }\n",
    "\n",
    "    if name not in dataset_loaders:\n",
    "        raise ValueError(f\"Dataset '{name}' no disponible o no es tabular.\")\n",
    "\n",
    "    # Cargar el conjunto de datos con 'as_frame=True' para obtener DataFrames de Pandas, si es compatible\n",
    "    load_function = dataset_loaders[name]\n",
    "    load_args = {}\n",
    "    if 'as_frame' in load_function.__code__.co_varnames:\n",
    "        load_args['as_frame'] = True\n",
    "    data = load_function(**load_args)\n",
    "\n",
    "    if hasattr(data, 'frame'):\n",
    "        X = data.frame.drop('target', axis=1)\n",
    "        y = data.frame['target']\n",
    "    else:\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "\n",
    "    # Dividir el conjunto de datos en entrenamiento, validación y prueba\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Ejemplo de cómo usar la función\n",
    "dataset_name = 'iris'  # Cambia esto por el nombre del conjunto de datos que quieras cargar\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_tabular_dataset(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'forest_covertypes'  \n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.926e+03, 2.200e+02, 1.200e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.092e+03, 3.380e+02, 3.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.836e+03, 2.190e+02, 1.700e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.968e+03, 2.100e+01, 1.100e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.719e+03, 6.300e+01, 2.300e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.007e+03, 4.200e+01, 7.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
