{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar funciones de procesamiento de datos\n",
    "from limpieza_datos import *\n",
    "\n",
    "# Importar la clase del modelo y funciones de entrenamiento/evaluación\n",
    "# from GNN import MultiKRWithGCN\n",
    "from train_and_evaluate import *\n",
    "\n",
    "from KGs import *\n",
    "\n",
    "# Importar funciones para modelar el EDA\n",
    "from edas import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar los datos y capturar los mapeos\n",
    "item_index_old2new, entity_id2index = read_item_index_to_entity_id_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_rating(item_index_old2new)\n",
    "entity_id2index, relation_id2index = convert_kg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga o genera edge_index una sola vez antes del entrenamiento\n",
    "edge_index = load_kg_and_create_edge_index(entity_id2index,relation_id2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de tipos de relaciones a tipos de entidades ajustado a tu descripción\n",
    "relation_to_entity_types = {\n",
    "    'book.book.genre': ('book', 'genre'),\n",
    "    'book.written_work.date_of_first_publication': ('book', 'date'),\n",
    "    'book.literary_series.author': ('series', 'author'),\n",
    "    'comic_books.series.publisher': ('comic_series', 'publisher'),\n",
    "    'book.written_work.author': ('book', 'author'),\n",
    "    'book.literary_series.works_in_this_series': ('series', 'work'),\n",
    "    'book.written_work.translation': ('original_work', 'translation'),\n",
    "    'book.written_work.subject': ('work', 'subject'),\n",
    "    'book.written_work.literary_series': ('work', 'series'),\n",
    "    'book.written_work.previous_in_series': ('work', 'previous_work'),\n",
    "}\n",
    "\n",
    "\n",
    "# Generar el mapeo de ID de entidad a tipo basado en el archivo kg.txt y el mapeo relation_to_entity_types\n",
    "entity_to_type = generate_entity_to_type_mapping('./MKR-data/kg.txt', relation_to_entity_types)\n",
    "\n",
    "# Mapeo de índice de relación a nombre de relación (debes definir este mapeo basado en tu datos)\n",
    "index_to_relation_name = {\n",
    "    0: 'book.book.genre',\n",
    "    1: 'book.written_work.date_of_first_publication',\n",
    "    2: 'book.literary_series.author',\n",
    "    3: 'comic_books.series.publisher',\n",
    "    4: 'book.written_work.author',\n",
    "    5: 'book.literary_series.works_in_this_series',\n",
    "    6: 'book.written_work.translation',\n",
    "    7: 'book.written_work.subject',\n",
    "    8: 'book.written_work.literary_series',\n",
    "    9: 'book.written_work.previous_in_series'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_file_path = './MKR-data/kg.txt'\n",
    "output_path = './MKR-data/'\n",
    "\n",
    "# Llama a la función como antes, omitiendo 'relation_id2index' y 'index_to_relation_name'\n",
    "# adapt_and_split_kg_data_with_slashes(entity_id2index, relation_to_entity_types, kg_file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos para el entrenamiento y la evaluación\n",
    "ratings = np.loadtxt('./MKR-data/ratings_final.txt', dtype=np.int32)\n",
    "train_data, eval_data, test_data = dataset_split(ratings)\n",
    "\n",
    "# Convertir los conjuntos de datos a DataLoader\n",
    "train_loader = DataLoader(TrainSet(train_data), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TrainSet(eval_data), batch_size=64, shuffle=True)\n",
    "eval_loader = DataLoader(TrainSet(test_data), batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training dataset summary:\")\n",
    "summarize_dataset(TrainSet(train_data))\n",
    "\n",
    "print(\"\\nEvaluation dataset summary:\")\n",
    "summarize_dataset(TrainSet(eval_data))\n",
    "\n",
    "# Comprobar una muestra de los datos cargados\n",
    "sample_user, sample_item, sample_target = next(iter(eval_loader))\n",
    "print(\"\\nSample batch from eval_loader:\")\n",
    "print(f\"User tensor: {sample_user}\")\n",
    "print(f\"Item tensor: {sample_item}\")\n",
    "print(f\"Target tensor: {sample_target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERSAMPLING NEGATIVO DE TRIPLETAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos del KG\n",
    "kg_data = np.loadtxt('./MKR-data/kg_final.txt', dtype=int)\n",
    "\n",
    "# Calcular el número total de entidades en el KG\n",
    "num_entities = max(np.max(kg_data[:, 0]), np.max(kg_data[:, 2])) + 1\n",
    "\n",
    "# # Generar ejemplos negativos para los datos del KG\n",
    "# kg_data_with_negatives = generate_kg_negative_samples(kg_data, num_entities, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crear mapeos inversos\n",
    "# index_to_entity_id = {v: k for k, v in entity_id2index.items()}\n",
    "# index_to_relation_id = {v: k for k, v in relation_id2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translate_triplet(triplet, index_to_entity_id, index_to_relation_id):\n",
    "#     head, relation, tail, is_positive = triplet\n",
    "#     head_id = index_to_entity_id.get(head, \"Unknown Entity\")\n",
    "#     tail_id = index_to_entity_id.get(tail, \"Unknown Entity\")\n",
    "#     relation_id = index_to_relation_id.get(relation, \"Unknown Relation\")\n",
    "#     return head_id, relation_id, tail_id, is_positive\n",
    "\n",
    "# def print_translated_triplets(samples, index_to_entity_id, index_to_relation_id):\n",
    "#     for sample in samples:\n",
    "#         translated = translate_triplet(sample, index_to_entity_id, index_to_relation_id)\n",
    "#         print(f\"{translated[0]}\\t{translated[1]}\\t{translated[2]}\\t{'Positive' if translated[3] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ejemplos de muestra positiva\n",
    "# print(\"Ejemplos de muestra positiva:\")\n",
    "# print_translated_triplets(kg_data_with_negatives[kg_data_with_negatives[:, 3] == 1][:5], index_to_entity_id, index_to_relation_id)\n",
    "\n",
    "# # Ejemplos de muestra negativa\n",
    "# print(\"\\nEjemplos de muestra negativa:\")\n",
    "# print_translated_triplets(kg_data_with_negatives[kg_data_with_negatives[:, 3] == 0][:5], index_to_entity_id, index_to_relation_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Supongamos que tienes kg_data con columnas [head, relation_id, tail]\n",
    "# relation_ids = kg_data[:, 1]  # Extraer los IDs de las relaciones del dataset\n",
    "\n",
    "# # Crear un mapeo de ID de relación a índice\n",
    "# unique_relation_ids = np.unique(relation_ids)\n",
    "# relation_id_to_index = {id: index for index, id in enumerate(unique_relation_ids)}\n",
    "\n",
    "# # Aplicar el mapeo a tu dataset para convertir IDs de relaciones a índices\n",
    "# mapped_relation_indices = np.array([relation_id_to_index[id] for id in relation_ids])\n",
    "\n",
    "# # Reemplazar la columna de ID de relaciones en kg_data por índices mapeados\n",
    "# kg_data[:, 1] = mapped_relation_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg_train_set=KGTrainSet(kg_data_with_negatives)\n",
    "kg_train_set=KGTrainSet(kg_data)\n",
    "kg_train_loader = DataLoader(kg_train_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos para el entrenamiento y la evaluación de recomendaciones\n",
    "ratings = np.loadtxt('./MKR-data/ratings_final.txt', dtype=np.int32)\n",
    "train_data, eval_data, test_data = dataset_split(ratings)\n",
    "\n",
    "# Convertir los conjuntos de datos a DataLoader para las recomendaciones\n",
    "rec_train_loader = DataLoader(TrainSet(train_data), batch_size=64, shuffle=True)\n",
    "rec_val_loader = DataLoader(TrainSet(eval_data), batch_size=64, shuffle=True)\n",
    "rec_eval_loader = DataLoader(TrainSet(test_data), batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo MultiKR\n",
    "user_num = len(np.unique(ratings[:, 0]))  # Número de usuarios únicos\n",
    "item_num = len(item_index_old2new)  # Número de ítems únicos\n",
    "entity_num = len(entity_id2index)  # Número de entidades únicas\n",
    "relation_num = len(np.unique(kg_data[:, 1])) # Número de relaciones únicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos para el entrenamiento de KG\n",
    "print(\"KG Training Dataset:\")\n",
    "print(f\"- Total triplets (with negatives): {len(kg_train_set)}\")\n",
    "print(f\"  (Cada tripleta incluye una entidad de cabeza, una relación, una entidad de cola, y una etiqueta indicando si es un ejemplo positivo o negativo)\")\n",
    "\n",
    "# Datos para el entrenamiento de recomendaciones\n",
    "print(\"\\nRecommendation Training Dataset:\")\n",
    "print(f\"- Total ratings (train): {len(train_data)}\")\n",
    "print(f\"- Total ratings (validation): {len(eval_data)}\")\n",
    "print(f\"- Total ratings (test): {len(test_data)}\")\n",
    "print(\"  (Cada rating incluye un usuario, un ítem, y una etiqueta indicando la interacción)\")\n",
    "\n",
    "# Información general sobre el modelo MultiKR\n",
    "print(\"\\nInformación General del Modelo MultiKR:\")\n",
    "print(f\"- Número de usuarios únicos: {user_num}\")\n",
    "print(f\"- Número de ítems únicos: {item_num} (ítems mapeados del KG a recomendaciones)\")\n",
    "print(f\"- Número de entidades únicas en el KG: {entity_num}\")\n",
    "print(f\"- Número de relaciones únicas en el KG: {relation_num}\")\n",
    "print(\"  (Esta configuración se utiliza para inicializar el modelo MultiKR, que integra datos de KG y recomendaciones)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos los siguientes parámetros\n",
    "n_layer = 1       # Número de capas en la red\n",
    "embed_dim = 50    # Dimensión de los embeddings\n",
    "hidden_layers = [64]  # Capas ocultas\n",
    "dropouts = [0.5]  # Dropout para cada capa\n",
    "output_rec = 1    # Salida para la recomendación\n",
    "activation_fn = 'leaky_relu'  # Función de activación\n",
    "\n",
    "kg_hyperparams={'batch_size': 256, 'epochs': 500, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
    "\n",
    "# Ruta al conjunto de datos KG\n",
    "kg_dataset_path = \"/home/victor/Escritorio/TFM/git/TFM/Victor/Codigo/GRAFOS/MKR-data/\"\n",
    "\n",
    "\n",
    "entity_embedding_path = \"/home/victor/Escritorio/TFM/git/TFM/Victor/Codigo/GRAFOS/MKR-data/embeddings/transe/ent_embedding.tsv\"\n",
    "relation_embedding_path = \"/home/victor/Escritorio/TFM/git/TFM/Victor/Codigo/GRAFOS/MKR-data/embeddings/transe/rel_embedding.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar AdvancedMultiKRWithPykg2vec\n",
    "model = AdvancedMultiKRWithPykg2vec(\n",
    "    user_num=user_num, \n",
    "    item_num=item_num, \n",
    "    entity_num=entity_num,\n",
    "    relation_num=relation_num,\n",
    "    n_layer=n_layer, \n",
    "    embed_dim=embed_dim,\n",
    "    hidden_layers=hidden_layers, \n",
    "    dropouts=dropouts, \n",
    "    output_rec=output_rec,\n",
    "    activation_fn=activation_fn, \n",
    "    kg_model_name='transe', \n",
    "    kg_hyperparams=kg_hyperparams,\n",
    "    kg_dataset_path=kg_dataset_path,\n",
    "    kg_trained=True,\n",
    "    entity_embedding_path = \"/home/victor/Escritorio/TFM/git/TFM/Victor/Codigo/GRAFOS/MKR-data/embeddings/transe/ent_embedding.tsv\",\n",
    "    relation_embedding_path = \"/home/victor/Escritorio/TFM/git/TFM/Victor/Codigo/GRAFOS/MKR-data/embeddings/transe/rel_embedding.tsv\",\n",
    "    freeze=False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ahora, entrena el modelo KG\n",
    "# model.train_kg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegúrate de inicializar el optimizador y la función de pérdida adecuados\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Ejecutar entrenamiento y evaluación\n",
    "train_and_evaluate_rec(model, rec_train_loader, rec_val_loader, optimizer, loss_function, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo variables y posibles valores para KG y Recomendación\n",
    "variables_kg, variables_rec = define_variables_for_KG_and_rec()\n",
    "\n",
    "# Combinar todas las variables y posibles valores en estructuras separadas\n",
    "# all_variables = list(variables_kg.keys()) + list(variables_rec.keys())\n",
    "# all_possible_values = list(variables_kg.values()) + list(variables_rec.values())\n",
    "\n",
    "combined_variables_and_values = {**variables_kg, **variables_rec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(variables_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_solution_kg(variables_kg), decode_solution_rec(variables_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir combined_variables_and_values en la estructura esperada por EBNA\n",
    "possible_values_numeric = {i: combined_variables_and_values[var] for i, var in enumerate(combined_variables_and_values)}\n",
    "frequency_numeric = {i: [1/len(possible_values_numeric[i])] * len(possible_values_numeric[i]) for i in possible_values_numeric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(possible_values_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertir posibles valores en una lista de listas para cada variable\n",
    "# possible_values_list = all_possible_values\n",
    "\n",
    "# # Inicializar la frecuencia uniforme para cada conjunto de valores posibles\n",
    "# frequency_list = [[1.0 / len(values) for _ in values] for values in possible_values_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EDAspy.optimization import EBNA\n",
    "\n",
    "# Inicializar EBNA con el espacio de soluciones y frecuencias definidas\n",
    "ebna = EBNA(\n",
    "    size_gen=20,\n",
    "    max_iter=20,\n",
    "    dead_iter=5,\n",
    "    n_variables=len(possible_values_numeric),\n",
    "    alpha=0.5,\n",
    "    possible_values=possible_values_numeric,\n",
    "    frequency=frequency_numeric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de envoltura para EBNA, pasando los parámetros necesarios\n",
    "multiKR_cost_wrapper_with_params = lambda solution: multiKR_cost_wrapper_eda(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar EBNA\n",
    "ebna_result = ebna.minimize(multiKR_cost_wrapper_with_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simular una entrada como la que esperaríamos de EBNA\n",
    "# solution_array = np.array([64, 0.001, 128, '64_128', 0.5, 1, 10])\n",
    "\n",
    "# # Llamar a decode_solution con esta entrada simulada\n",
    "# decoded_solution = decode_solution(solution_array)\n",
    "# print(\"Decoded solution:\", decoded_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper_result = multiKR_cost_wrapper(decoded_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Entrenamiento de prueba\n",
    "\n",
    "# print(\"Wrapper result:\", wrapper_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
