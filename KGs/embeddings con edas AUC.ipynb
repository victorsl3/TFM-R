{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from EDAspy.optimization import UMDAc\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importaciones de tus módulos personalizados\n",
    "from limpieza_datos import read_item_index_to_entity_id_file, convert_rating, convert_kg, dataset_split, TrainSet\n",
    "from custom_mkr import MultiKR\n",
    "from train_and_evaluate import train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64  # Dimensionalidad de los embeddings\n",
    "\n",
    "def initialize_population(entity_num, relation_num, embed_dim):\n",
    "    # Genera embeddings iniciales con las dimensiones adecuadas.\n",
    "    entity_population = np.random.rand(entity_num, embed_dim)\n",
    "    relation_population = np.random.rand(relation_num, embed_dim)\n",
    "    return entity_population, relation_population\n",
    "\n",
    "\n",
    "def auc_cost_function(entity_pop, relation_pop, model, train_loader, val_loader, optimizer, loss_function, epoch=5):\n",
    "    # print(\"Shape of entity_pop:\", entity_pop.shape)\n",
    "    # print(\"Shape of relation_pop:\", relation_pop.shape)\n",
    "    # print(\"Expected shape of model's entity embeddings:\", model.entity_embed.weight.shape)\n",
    "    # print(\"Expected shape of model's relation embeddings:\", model.relation_embed.weight.shape)\n",
    "\n",
    "    # print(\"New entity embeddings:\", entity_pop[:1]) \n",
    "    # print(\"New relation embeddings:\", relation_pop[:1])  \n",
    "\n",
    "\n",
    "    # Asignar embeddings verificando las formas\n",
    "    if entity_pop.shape == model.entity_embed.weight.shape and relation_pop.shape == model.relation_embed.weight.shape:\n",
    "        model.entity_embed.weight.data = torch.tensor(entity_pop, dtype=torch.float32, device=model.entity_embed.weight.device)\n",
    "        model.relation_embed.weight.data = torch.tensor(relation_pop, dtype=torch.float32, device=model.relation_embed.weight.device)\n",
    "    else:\n",
    "        print(\"Mismatch in embedding shapes!\")\n",
    "        return float('inf')  # Retorna un valor de 'infinito' si hay un error en las formas\n",
    "\n",
    "    _, _, val_auc = train_and_evaluate(model, train_loader, val_loader, optimizer, loss_function, num_epochs=epoch, task_type='rec', edge_index=None, relation_index=None)\n",
    "    return -val_auc\n",
    "\n",
    "\n",
    "\n",
    "def run_eda(entity_num, relation_num, embed_dim, model, train_loader, val_loader, population_size=10,max_iter=150, dead_iter=10,lower_bound=0, upper_bound=1,alpha=0.5  ):\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "    loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "    epoch=5\n",
    "\n",
    "    # UMDAc con el número correcto de variables: cada dimensión de cada embedding es una variable.\n",
    "    umda = UMDAc(\n",
    "        size_gen=population_size,\n",
    "        max_iter=max_iter,\n",
    "        dead_iter=dead_iter,\n",
    "        n_variables=(entity_num + relation_num) * embed_dim,  # Total de dimensiones para todas las entidades y relaciones\n",
    "        lower_bound=lower_bound,\n",
    "        upper_bound=upper_bound,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "    # La función lambda reconstruye los embeddings a partir del vector plano optimizado por el EDA.\n",
    "    cost_function_wrapper = lambda x: auc_cost_function(\n",
    "                                                        x[:entity_num * embed_dim].reshape(entity_num, embed_dim),\n",
    "                                                        x[entity_num * embed_dim:(entity_num + relation_num) * embed_dim].reshape(relation_num, embed_dim),\n",
    "                                                        model, train_loader, val_loader, optimizer, loss_function, epoch\n",
    "    )\n",
    "    umda_result = umda.minimize(cost_function_wrapper)\n",
    "    return umda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de datos y modelo\n",
    "_, entity_id2index = read_item_index_to_entity_id_file()\n",
    "convert_rating(_)\n",
    "entity_id2index, relation_id2index = convert_kg()\n",
    "ratings = np.loadtxt('./MKR-data/ratings_final.txt', dtype=np.int32)\n",
    "train_data, eval_data, test_data = dataset_split(ratings)\n",
    "train_loader = DataLoader(TrainSet(train_data), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TrainSet(eval_data), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TrainSet(test_data), batch_size=64, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_id2index ## COMPROBAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_indices_in_dataloader(data_loader):\n",
    "    max_user_idx, max_item_idx = 0, 0\n",
    "    for data in data_loader:\n",
    "        user, item, _ = data\n",
    "        max_user_idx = max(max_user_idx, user.max().item())\n",
    "        max_item_idx = max(max_item_idx, item.max().item())\n",
    "    print(f'Max user index in DataLoader: {max_user_idx}')\n",
    "    print(f'Max item index in DataLoader: {max_item_idx}')\n",
    "\n",
    "check_indices_in_dataloader(train_loader)\n",
    "check_indices_in_dataloader(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = len(np.unique(ratings[:, 0]))\n",
    "item_num = len(np.unique(ratings[:, 1]))\n",
    "entity_num = len(entity_id2index)\n",
    "relation_num = len(relation_id2index)\n",
    "\n",
    "print([user_num, item_num, entity_num, relation_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [64 0.0001 64 '64' 0.3 1 5]\n",
    "\n",
    "\n",
    "# 'batch_size': [32, 64, 128],\n",
    "# 'lr': [0.01, 0.001, 0.0001],\n",
    "# 'embed_dim': [64, 128, 256],\n",
    "# 'hidden_layers_config': [\n",
    "#     '64', '128', '256',  # Configuraciones de una sola capa\n",
    "#     '64_64', '128_128', '256_256',  # Configuraciones de dos capas iguales\n",
    "#     '64_128', '128_256',  # Configuraciones de dos capas crecientes\n",
    "#     '128_64', '256_128',  # Configuraciones de dos capas decrecientes\n",
    "#     '64_128_256', '256_128_64',  # Configuraciones de tres capas\n",
    "#     '64_64_64', '128_128_128', '256_256_256',  # Configuraciones de tres capas iguales\n",
    "# ],\n",
    "# 'dropout_rate': [0.5, 0.3, 0.1],\n",
    "# 'output_rec': [1],\n",
    "# 'epochs': [5, 10, 15]  # Agrega los valores deseados para epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el máximo índice usado para usuarios e ítems\n",
    "max_user_idx = ratings[:, 0].max()\n",
    "max_item_idx = ratings[:, 1].max()\n",
    "\n",
    "# Configuración del modelo utilizando estos máximos\n",
    "model = MultiKR(\n",
    "    user_num=max_user_idx + 1,  # todos los índices de usuario desde 0 hasta max_user_idx\n",
    "    item_num=max_item_idx + 1,  # todos los índices de ítem desde 0 hasta max_item_idx\n",
    "    entity_num=len(entity_id2index),  \n",
    "    relation_num=len(relation_id2index),  \n",
    "    n_layer=1,\n",
    "    embed_dim=64,\n",
    "    hidden_layers=[64], \n",
    "    dropouts=[0.3],\n",
    "    output_rec=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inicialización del modelo\n",
    "# model = MultiKR(user_num=user_num, item_num=item_num, entity_num=entity_num, relation_num=relation_num, n_layer=2, embed_dim=64, hidden_layers=[128, 64], dropouts=[0.5, 0.5], output_rec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forma esperada de embeddings de entidades:\", model.entity_embed.weight.data.shape)\n",
    "print(\"Forma esperada de embeddings de relaciones:\", model.relation_embed.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Ejecutar EDA\n",
    "best_embeddings = run_eda(entity_num, relation_num, embed_dim, model, train_loader, val_loader, population_size=25,max_iter=150, dead_iter=10,lower_bound=-1, upper_bound=1,alpha=0.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal embeddings found:\", best_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar EDA\n",
    "best_embeddings2 = run_eda(entity_num, relation_num, embed_dim, model, train_loader, val_loader, population_size=30,max_iter=150, dead_iter=10,lower_bound=-1, upper_bound=1,alpha=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal embeddings found:\", best_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar EDA\n",
    "best_embeddings3 = run_eda(entity_num, relation_num, embed_dim, model, train_loader, val_loader, population_size=50,max_iter=150, dead_iter=15,lower_bound=-1, upper_bound=1,alpha=0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal embeddings found:\", best_embeddings3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
