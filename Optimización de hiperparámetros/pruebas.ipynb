{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de Python: 3.8.18 (default, Sep 11 2023, 13:40:15) \n",
      "[GCC 11.2.0]\n",
      "Versión de PyTorch: 2.3.0+cu121\n",
      "Versión de CUDA disponible: 12.1\n",
      "2.3.0+cu121\n",
      "CUDA disponible: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA disponible:\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNombre del dispositivo CUDA:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# ## Carga del modelo\u001b[39;00m\n\u001b[1;32m     46\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoImageProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/resnet-50\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/conda/envs/framework/lib/python3.8/site-packages/torch/cuda/__init__.py:414\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/conda/envs/framework/lib/python3.8/site-packages/torch/cuda/__init__.py:444\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/conda/envs/framework/lib/python3.8/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    " \n",
    "# ### Librerias\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import copy\n",
    "import EDAspy2\n",
    "import sys\n",
    "sys.path.append(\"/home/v839/v839190/Hip\")\n",
    "from EDAspy2.optimization import EBNA\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "\n",
    "\n",
    "root_data=\"/home/v839/v839190/poda/poda efficientnet/data/\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Comprobar la versión de Python\n",
    "print(f\"Versión de Python: {sys.version}\")\n",
    "\n",
    "# Comprobar la versión de PyTorch\n",
    "print(f\"Versión de PyTorch: {torch.__version__}\")\n",
    "\n",
    "# Comprobar la versión de CUDA disponible para PyTorch\n",
    "print(f\"Versión de CUDA disponible: {torch.version.cuda}\")\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print('CUDA disponible:', torch.cuda.is_available())\n",
    "print('Nombre del dispositivo CUDA:', torch.cuda.get_device_name(0))\n",
    "\n",
    " \n",
    "# ## Carga del modelo\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "\n",
    "model = model.eval()  # Poner el modelo en modo de evaluación\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transform = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    " \n",
    "# \n",
    "# ## Paso 1: Inicialización\n",
    "# \n",
    "# - **Recopilación de Datos Iniciales**: Evaluar el modelo para obtener un conjunto inicial de métricas de rendimiento que pueden incluir la precisión de la clasificación, la pérdida de la red, o cualquier otra métrica relevante.\n",
    "# - **Determinación de Importancia de Pesos**: Inicialmente, se puede utilizar un criterio simple como la magnitud del peso o una evaluación de la contribución del peso al gradiente para clasificar los pesos según su importancia.\n",
    "\n",
    " \n",
    "# ### 1.1 Carga de datos\n",
    "\n",
    "\n",
    "# Define las rutas a los archivos\n",
    "loc_synset_mapping_path = root_data+'LOC_synset_mapping.txt'\n",
    "ids_path = root_data+'ids.txt'\n",
    "\n",
    "# Inicializa un diccionario para el mapeo de Synset ID a Etiqueta Numérica\n",
    "synset_to_num = {}\n",
    "# Inicializa un diccionario para el mapeo de Etiqueta Numérica a Descripción Humana\n",
    "num_to_human = {}\n",
    "\n",
    "# Leer LOC_synset_mapping.txt y construir ambos mapeos\n",
    "with open(loc_synset_mapping_path, 'r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        parts = line.strip().split(' ', 1)\n",
    "        synset_id = parts[0]\n",
    "        human_readable = parts[1] if len(parts) > 1 else \"\"\n",
    "\n",
    "        # Asignar el índice como etiqueta numérica al synset ID\n",
    "        synset_to_num[synset_id] = index\n",
    "        # Asignar la descripción humana a la etiqueta numérica\n",
    "        num_to_human[index] = human_readable\n",
    "\n",
    "# Opcionalmente, imprime los primeros elementos de cada mapeo para verificar\n",
    "print(\"Synset to Numeric Label Mapping (sample):\", list(synset_to_num.items())[:5])\n",
    "print(\"Numeric Label to Human-readable Mapping (sample):\", list(num_to_human.items())[:5])\n",
    "\n",
    "# Si necesitas el mapeo inverso de etiquetas numéricas a Synset IDs (por ejemplo, para usar con ids.txt),\n",
    "# puedes invertir el diccionario synset_to_num así:\n",
    "num_to_synset = {v: k for k, v in synset_to_num.items()}\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, synset_to_num):\n",
    "        self.dataset = dataset\n",
    "        self.synset_to_num = synset_to_num\n",
    "        # Invertir el mapeo de clase a índice de ImageFolder para obtener Synset IDs a partir de etiquetas de ImageFolder\n",
    "        self.idx_to_synset = {v: k for k, v in self.dataset.class_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        # Convertir la etiqueta de ImageFolder a Synset ID y luego a tu etiqueta numérica personalizada\n",
    "        synset_id = self.idx_to_synset[label]\n",
    "        custom_label = self.synset_to_num[synset_id]\n",
    "        return img, custom_label\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_dir = root_data+'imagenes'\n",
    "\n",
    "# Transformaciones (asumiendo que ya las has definido)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Cargar todas las imágenes con ImageFolder\n",
    "all_data = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Envolver el dataset de ImageFolder en tu CustomDataset\n",
    "custom_all_data = CustomDataset(all_data, synset_to_num)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "train_size = int(0.6 * len(custom_all_data))  # 60% de los datos para entrenamiento\n",
    "valid_size = int(0.2 * len(custom_all_data))  # 20% de los datos para validación\n",
    "test_size = len(custom_all_data) - train_size - valid_size  # El resto para prueba\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(custom_all_data, [train_size, valid_size, test_size])\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def load_data_to_device(data_loader, device):\n",
    "    for images, labels in tqdm(data_loader, desc='Loading data to device'):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "# for images, labels in train_loader:\n",
    "#     images = images.to(device)\n",
    "#     labels = labels.to(device)\n",
    "load_data_to_device(train_loader, device)\n",
    "\n",
    "\n",
    "for images, labels in valid_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean  # desnormalizar\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=12)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Obtener un batch de imágenes y etiquetas del DataLoader de entrenamiento\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Convertir la etiqueta numérica a descripción legible por humanos\n",
    "label_text = [num_to_human[label.item()] for label in labels]  # Convertir todas las etiquetas del batch\n",
    "\n",
    "# Mostrar imágenes y etiquetas\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # Ajusta el tamaño según sea necesario\n",
    "\n",
    "# Visualizar la primera imagen del batch con descripción legible por humanos como título\n",
    "imshow(images[0], label_text[0])\n",
    "\n",
    " \n",
    "# ### 1.2 Evaluación\n",
    "\n",
    "\n",
    "# Función para evaluar el modelo\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model = model.to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\", leave=True):\n",
    "            # model.to(device)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            _, predicted = torch.max(outputs.logits, 1)  # Corregido\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test images: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Evaluar el modelo\n",
    "evaluate_model(model, test_loader, device)\n",
    "\n",
    " \n",
    "# ## 1.3 NTK\n",
    "\n",
    " \n",
    "# ### NTK aproximado\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_weight_perturbation(model, epsilon=1e-5, device='cuda'):\n",
    "    # Esta función crea un diccionario de perturbaciones para los parámetros del modelo\n",
    "    delta_theta = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:  # Solo se consideran los pesos para la perturbación\n",
    "            perturbation = torch.randn_like(param).to(device) * epsilon\n",
    "            delta_theta[name] = perturbation\n",
    "    return delta_theta\n",
    "\n",
    "def compute_ntk_approx(model, data_loader, device, epsilon=1e-5):\n",
    "    model.eval()  # Ponemos el modelo en modo de evaluación para desactivar Dropout, etc.\n",
    "    ntk_approximations = []\n",
    "\n",
    "    # Asegurarnos de que no calculamos gradientes hasta que sea necesario\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in tqdm(data_loader, desc='Computing NTK Approximation'):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Activamos los gradientes solo para la sección que los necesita\n",
    "            with torch.enable_grad():\n",
    "                outputs_original = model(inputs)\n",
    "                logits_original = outputs_original if isinstance(outputs_original, torch.Tensor) else outputs_original.logits\n",
    "                logits_sum = logits_original.sum()  # Suma para poder llamar backward\n",
    "                logits_sum.backward(retain_graph=True)  # Calculamos gradientes para los pesos originales\n",
    "                grad_original = torch.cat([param.grad.view(-1) for param in model.parameters() if param.requires_grad])\n",
    "                model.zero_grad()  # Limpiamos los gradientes para la siguiente pasada\n",
    "\n",
    "            # Aplicamos la perturbación y calculamos los gradientes con los pesos perturbados\n",
    "            delta_theta = sample_weight_perturbation(model, epsilon, device)\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in delta_theta:\n",
    "                    param.data.add_(delta_theta[name])\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                logits_perturbed = model(inputs).logits\n",
    "                logits_perturbed.sum().backward()  # Calculamos gradientes para los pesos perturbados\n",
    "                grad_perturbed = torch.cat([param.grad.view(-1) for param in model.parameters() if param.requires_grad])\n",
    "\n",
    "            # Restauramos los pesos originales del modelo\n",
    "            with torch.no_grad():\n",
    "                for name, param in model.named_parameters():\n",
    "                    if name in delta_theta:\n",
    "                        param.data.sub_(delta_theta[name])\n",
    "\n",
    "            # Calculamos la aproximación de la norma nuclear del NTK para este mini-batch\n",
    "            ntk_approximation = ((grad_original - grad_perturbed).norm() ** 2) / (epsilon ** 2)\n",
    "            ntk_approximations.append(ntk_approximation.item())\n",
    "\n",
    "    ntk_nuclear_norm_approx = sum(ntk_approximations) / len(ntk_approximations)\n",
    "    return ntk_nuclear_norm_approx\n",
    "\n",
    " \n",
    "# ### NTK de referencia\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f\"Gradient not required for {name}\")\n",
    "\n",
    "\n",
    "# Asegúrate de que 'model', 'valid_loader', y 'device' están definidos y configurados correctamente\n",
    "ntk_approx = compute_ntk_approx(model, valid_loader, device)\n",
    "\n",
    "\n",
    "referencia=ntk_approx\n",
    "referencia\n",
    "\n",
    " \n",
    "# ## Paso 2: Construcción del Modelo Probabilístico\n",
    "# \n",
    "# - **Modelado de la Importancia de los Pesos**: Utilizar los datos recopilados para construir un modelo probabilístico que asocie la importancia de los pesos con su impacto en el rendimiento de la red. Este modelo se actualizará iterativamente para reflejar el aprendizaje adquirido sobre la distribución de la importancia de los pesos.\n",
    "# - **Aplicación de EDAs**: Implementar un EDA para muestrear y evaluar configuraciones de pesos según el modelo probabilístico.\n",
    "\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        # Acceder a los pesos\n",
    "        weights = module.weight.data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_pruning_mask(model, param_configuration, exclude_layers_prefixes=['classifier', 'pooler', 'embedder'], exclude_types=['norm']):\n",
    "    \"\"\"\n",
    "    Crea una máscara de poda para el modelo basada en la configuración de parámetros dada.\n",
    "    Excluye la poda de capas específicas cuyos nombres contienen algún prefijo en exclude_layers_prefixes\n",
    "    y también excluye los tipos de capas específicos como BatchNorm.\n",
    "    \"\"\"\n",
    "    mask = {}\n",
    "    idx = 0  # Índice para recorrer la configuración de parámetros\n",
    "    for name, param in model.named_parameters():\n",
    "        # Determinar si se debe excluir la capa\n",
    "        exclude = False\n",
    "        \n",
    "        # Excluir capas por prefijo\n",
    "        for excluded_prefix in exclude_layers_prefixes:\n",
    "            if excluded_prefix in name:\n",
    "                exclude = True\n",
    "                break  # No necesita comprobar otros prefijos\n",
    "        \n",
    "        # Excluir tipos de capas específicos\n",
    "        if not exclude:  # Solo si no se ha excluido por prefijo\n",
    "            for exclude_type in exclude_types:\n",
    "                if exclude_type in name:\n",
    "                    exclude = True\n",
    "                    break  # No necesita comprobar otros tipos\n",
    "        \n",
    "        if exclude:\n",
    "            # Si se excluye, crear una máscara de unos del mismo tamaño que el parámetro\n",
    "            mask[name] = torch.ones_like(param)\n",
    "        else:\n",
    "            # Si no se excluye, crear la máscara basada en la configuración de parámetros\n",
    "            param_numel = param.numel()  # Número de elementos en el parámetro actual\n",
    "            current_param_config = param_configuration[idx:idx+param_numel]\n",
    "            mask[name] = torch.tensor(current_param_config, device=param.device).view_as(param)\n",
    "            idx += param_numel  # Avanzar en el índice de configuración de parámetros\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def apply_pruning_mask(model, pruning_mask):\n",
    "    \"\"\"\n",
    "    Aplica la máscara de poda al modelo. Los pesos con un valor de máscara de cero se 'podan'.\n",
    "    \"\"\"\n",
    "    pruned_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        before_pruning = torch.count_nonzero(param.data)\n",
    "        param.data.mul_(pruning_mask[name])\n",
    "        after_pruning = torch.count_nonzero(param.data)\n",
    "        pruned_count = before_pruning - after_pruning\n",
    "\n",
    "        # Extraer el tipo de capa y subcomponentes para un seguimiento más detallado\n",
    "        path_parts = name.split('.')\n",
    "        layer_detail = path_parts[1] if len(path_parts) > 1 else 'other'\n",
    "        subcomponent = path_parts[-1]  # Puede ser 'weight', 'bias', etc.\n",
    "\n",
    "        # Concatenar para obtener una clasificación detallada\n",
    "        detail_key = f\"{layer_detail}.{subcomponent}\"\n",
    "\n",
    "        if detail_key in pruned_params:\n",
    "            pruned_params[detail_key] += pruned_count\n",
    "        else:\n",
    "            pruned_params[detail_key] = pruned_count\n",
    "\n",
    "    # Ordenar y imprimir los resultados de la poda de manera más estructurada\n",
    "    print(\"Resumen detallado de parámetros podados:\")\n",
    "    for detail_key, count in sorted(pruned_params.items()):\n",
    "        print(f\"{detail_key}: {count} parámetros podados\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Ajuste de n_variables para cubrir todos los parámetros del modelo\n",
    "n_variables = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "original_model = copy.deepcopy(model)  # Hace una copia profunda del modelo original\n",
    "possible_values = [[0, 1] for _ in range(n_variables)]\n",
    "frequency = [[0.999, 0.001] for _ in range(n_variables)]\n",
    "#frequency = [[0.5, 0.5] for _ in range(n_variables)]\n",
    "\n",
    "\n",
    "\n",
    "n_variables_total = sum(p.numel() for p in model.parameters())\n",
    "n_variables_total\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_accuracy_loss(model, data_loader, device, criterion):\n",
    "    model.eval()  # Cambia el modelo a modo de evaluación\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        # Utiliza tqdm para visualizar el progreso\n",
    "        for inputs, targets in tqdm(data_loader, desc=\"Evaluación\", leave=True):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
    "            loss = criterion(logits, targets)  # Utiliza los logits aquí\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = logits.max(1)  # Usa logits para obtener las predicciones\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    # Calcula la precisión y la pérdida promedio\n",
    "    if total > 0:\n",
    "        accuracy = 100 * correct / total\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        return avg_loss, accuracy\n",
    "    else:\n",
    "        return 0, 0  # Devuelve 0 para evitar errores en caso de que no se procesen datos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, device, epochs, lr, pruning_mask=None, early_stopping_patience=3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # Envuelve el cargador de entrenamiento con tqdm para la barra de progreso\n",
    "        train_progress_bar = tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{epochs}', leave=False)\n",
    "        for inputs, targets in train_progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            if pruning_mask is not None:\n",
    "                for name, param in model.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        param.grad.data.mul_(pruning_mask[name])\n",
    "\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Actualiza la barra de progreso de tqdm con la última pérdida y precisión\n",
    "            train_progress_bar.set_postfix(loss=loss.item(), accuracy=f\"{100. * correct / total:.2f}%\")\n",
    "\n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        train_accuracies.append(100. * correct / total)\n",
    "\n",
    "        # Evaluar en el conjunto de validación\n",
    "        valid_loss, valid_accuracy = evaluate_accuracy_loss(model, valid_loader, device, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        # Actualizar el scheduler con la pérdida de validación\n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.2f}%, Valid Loss: {valid_losses[-1]:.4f}, Valid Acc: {valid_accuracies[-1]:.2f}%\")\n",
    "\n",
    "        # Verificar early stopping\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "            break\n",
    "\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies\n",
    "\n",
    "def get_next_individual_id(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for i, l in enumerate(f):\n",
    "                pass\n",
    "        return i + 1\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import torch\n",
    "\n",
    "def fitness_function(original_model, train_loader, valid_loader, device, config, ntk_ref, epochs=3, lr=0.001):\n",
    "    # Archivo para guardar el contador de ejecuciones\n",
    "    counter_filename = '/home/v839/v839190/poda/poda efficientnet/execution_count.txt'\n",
    "\n",
    "    # Leer el contador actual o inicializarlo si el archivo no existe\n",
    "    try:\n",
    "        with open(counter_filename, 'r') as file:\n",
    "            execution_count = int(file.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        execution_count = 0\n",
    "\n",
    "    # Incrementar el contador\n",
    "    execution_count += 1\n",
    "    print(f\"Ejecución número: {execution_count}\")\n",
    "    # Escribir el nuevo valor del contador en el archivo\n",
    "    with open(counter_filename, 'w') as file:\n",
    "        file.write(str(execution_count))\n",
    "\n",
    "    # Mover el modelo original fuera del dispositivo para ahorrar memoria\n",
    "    original_model.cpu()\n",
    "\n",
    "    # Clonar y preparar el modelo para la poda y el entrenamiento\n",
    "    cloned_model = copy.deepcopy(original_model)\n",
    "    cloned_model.to(device)\n",
    "\n",
    "    # Crear y aplicar la máscara de poda basada en la configuración\n",
    "    pruning_mask = create_pruning_mask(cloned_model, config)\n",
    "    cloned_model = apply_pruning_mask(cloned_model, pruning_mask)\n",
    "\n",
    "    # Decidir si entrenar o rellenar con ceros basándose en el contador\n",
    "    if execution_count % 100 == 0:\n",
    "        # Entrenar el modelo y obtener las métricas\n",
    "        train_losses, train_accuracies, valid_losses, valid_accuracies = train_model(\n",
    "            cloned_model, train_loader, valid_loader, device, epochs, lr, pruning_mask\n",
    "        )\n",
    "    else:\n",
    "        # Rellenar los arrays con ceros si no es momento de entrenar\n",
    "        train_losses, train_accuracies, valid_losses, valid_accuracies = ([0], [0], [0], [0])\n",
    "\n",
    "    # Calcular la norma nuclear aproximada del NTK después del entrenamiento\n",
    "    ntk_approx = compute_ntk_approx(cloned_model, valid_loader, device)\n",
    "\n",
    "    # Calcula la diferencia absoluta con la norma nuclear de referencia del NTK\n",
    "    cost = abs(ntk_ref - ntk_approx) \n",
    "\n",
    "    # Mover el modelo podado de vuelta a la CPU para liberar memoria GPU\n",
    "    cloned_model.cpu()\n",
    "    # Limpia la caché de la GPU si es necesario\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Obtener el ID del individuo basándose en el número de registros en el archivo\n",
    "    filename = '/home/v839/v839190/poda/poda efficientnet/individual_info.txt'\n",
    "    individual_id = get_next_individual_id(filename)\n",
    "\n",
    "    # Información del individuo\n",
    "    individual_info = {\n",
    "        'id': individual_id,\n",
    "        'number_of_parameters': sum(p.numel() for p in cloned_model.parameters()),\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'validation_loss': valid_losses,\n",
    "        'validation_accuracy': valid_accuracies,\n",
    "        'ntk_nuclear_norm': ntk_approx,\n",
    "        'ntk_difference': cost\n",
    "    }\n",
    "\n",
    "    # Registrar información del individuo en archivo de texto\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(json.dumps(individual_info) + '\\n')\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == False:\n",
    "        print(name, \"has requires_grad set to False\")\n",
    "\n",
    "\n",
    "\n",
    "import EDAspy2\n",
    "from EDAspy2.optimization import UMDAd\n",
    "\n",
    "\n",
    "umda = UMDAd(\n",
    "    size_gen=10,\n",
    "    max_iter=120,\n",
    "    dead_iter=8,\n",
    "    n_variables=n_variables,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Definir una función lambda que envuelva la llamada a fitness_function con los parámetros necesarios\n",
    "wrapped_fitness_function = lambda config: fitness_function(\n",
    "    original_model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    device,\n",
    "    config,  # config se pasa directamente desde el eda\n",
    "    referencia,\n",
    "    epochs=10,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Ejecutar EDA con la función lambda\n",
    "best_solution = umda.minimize(wrapped_fitness_function)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
